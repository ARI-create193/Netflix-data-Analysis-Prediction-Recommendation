{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio pandas matplotlib seaborn wordcloud numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfohtuRLBkho",
        "outputId": "6b2d27f9-7e1d-4daa-dd0c-075a40cee274"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.38.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (2025.7.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Netflix Data Analysis Dashboard with Gradio\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gradio as gr\n",
        "import io\n",
        "import base64\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import joblib\n",
        "\n",
        "# Set matplotlib backend and style\n",
        "plt.switch_backend('Agg')\n",
        "plt.style.use('default')\n",
        "\n",
        "class NetflixAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.sample_data = self.create_sample_data()\n",
        "        self.ml_model = None\n",
        "        self.label_encoders = {}\n",
        "        self.scaler = StandardScaler()\n",
        "        self.tfidf_vectorizer = None\n",
        "        self.content_features = None\n",
        "\n",
        "    def create_sample_data(self):\n",
        "        \"\"\"Create sample data for demonstration\"\"\"\n",
        "        sample_data = {\n",
        "            'show_id': ['s1', 's3', 's6', 's14', 's8', 's20', 's25', 's30', 's35', 's40',\n",
        "                       's45', 's50', 's55', 's60', 's65', 's70', 's75', 's80', 's85', 's90'],\n",
        "            'type': ['Movie', 'TV Show', 'TV Show', 'Movie', 'Movie', 'Movie', 'TV Show',\n",
        "                    'Movie', 'TV Show', 'Movie', 'Movie', 'TV Show', 'Movie', 'TV Show',\n",
        "                    'Movie', 'TV Show', 'Movie', 'Movie', 'TV Show', 'Movie'],\n",
        "            'title': ['Dick Johnson Is Dead', 'Ganglands', 'Midnight Mass', 'Confessions of an Invisible Girl',\n",
        "                     'Sankofa', 'The Social Dilemma', 'Stranger Things', 'Extraction', 'The Crown',\n",
        "                     'Bird Box', 'Roma', 'Money Heist', 'The Irishman', 'Dark', 'Marriage Story',\n",
        "                     'Black Mirror', 'Klaus', 'The Platform', 'Ozark', 'Okja'],\n",
        "            'director': ['Kirsten Johnson', 'Julien Leclercq', 'Mike Flanagan', 'Bruno Garotti',\n",
        "                        'Haile Gerima', 'Jeff Orlowski', 'Matt Duffer', 'Sam Hargrave',\n",
        "                        'Peter Morgan', 'Susanne Bier', 'Alfonso Cuarón', 'Álex Pina', 'Martin Scorsese',\n",
        "                        'Baran bo Odar', 'Noah Baumbach', 'Charlie Brooker', 'Sergio Pablos',\n",
        "                        'Galder Gaztelu-Urrutia', 'Jason Bateman', 'Bong Joon-ho'],\n",
        "            'country': ['United States', 'France', 'United States', 'Brazil', 'United States',\n",
        "                       'United States', 'United States', 'United States', 'United Kingdom',\n",
        "                       'United States', 'Mexico', 'Spain', 'United States', 'Germany',\n",
        "                       'United States', 'United Kingdom', 'Spain', 'Spain', 'United States', 'South Korea'],\n",
        "            'date_added': ['9/25/2021', '9/24/2021', '9/24/2021', '9/22/2021', '9/24/2021',\n",
        "                          '9/9/2020', '7/15/2019', '4/24/2020', '11/9/2019', '12/21/2018',\n",
        "                          '12/14/2018', '12/20/2017', '11/27/2019', '6/27/2020', '12/6/2019',\n",
        "                          '6/5/2019', '11/15/2019', '3/20/2020', '7/21/2017', '6/28/2017'],\n",
        "            'release_year': [2020, 2021, 2021, 2021, 1993, 2020, 2016, 2020, 2016, 2018,\n",
        "                            2018, 2017, 2019, 2017, 2019, 2011, 2019, 2019, 2017, 2017],\n",
        "            'rating': ['PG-13', 'TV-MA', 'TV-MA', 'TV-PG', 'TV-MA', 'PG-13', 'TV-14', 'R',\n",
        "                      'TV-MA', 'R', 'R', 'TV-MA', 'R', 'TV-MA', 'R', 'TV-MA', 'PG', 'TV-MA',\n",
        "                      'TV-MA', 'TV-PG'],\n",
        "            'duration': ['90 min', '1 Season', '1 Season', '91 min', '125 min', '94 min',\n",
        "                        '4 Seasons', '116 min', '4 Seasons', '124 min', '135 min', '5 Seasons',\n",
        "                        '209 min', '3 Seasons', '137 min', '5 Seasons', '96 min', '104 min',\n",
        "                        '4 Seasons', '118 min'],\n",
        "            'listed_in': ['Documentaries', 'Crime TV Shows, International TV Shows', 'TV Dramas, Horror TV Shows',\n",
        "                         'Children & Family Movies, Comedies', 'Dramas, Independent Movies', 'Documentaries',\n",
        "                         'TV Dramas, TV Sci-Fi & Fantasy', 'Action & Adventure, Thrillers', 'British TV Shows, TV Dramas',\n",
        "                         'Horror Movies, Thrillers', 'Dramas, International Movies', 'Crime TV Shows, International TV Shows',\n",
        "                         'Crime Movies, Dramas', 'Crime TV Shows, International TV Shows', 'Dramas, Independent Movies',\n",
        "                         'British TV Shows, TV Sci-Fi & Fantasy', 'Children & Family Movies, Comedies',\n",
        "                         'Horror Movies, International Movies', 'Crime TV Shows, TV Dramas', 'Children & Family Movies, Comedies']\n",
        "        }\n",
        "        return pd.DataFrame(sample_data)\n",
        "\n",
        "    def get_sample_data_table(self):\n",
        "        \"\"\"Return sample data as HTML table for display\"\"\"\n",
        "        try:\n",
        "            if self.data is not None:\n",
        "                display_data = self.data.head(10)\n",
        "            else:\n",
        "                display_data = self.sample_data.head(10)\n",
        "\n",
        "            # Convert to HTML table with styling\n",
        "            html_table = display_data.to_html(index=False, classes='table table-striped', escape=False)\n",
        "            return html_table\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error displaying sample data: {str(e)}\"\n",
        "\n",
        "    def load_data(self, file):\n",
        "        \"\"\"Load data from uploaded file or use sample data\"\"\"\n",
        "        try:\n",
        "            if file is not None:\n",
        "                self.data = pd.read_csv(file.name)\n",
        "                return f\"✅ Data loaded successfully! Shape: {self.data.shape}\"\n",
        "            else:\n",
        "                self.data = self.sample_data.copy()\n",
        "                return \"📊 Using sample Netflix data for demonstration.\"\n",
        "        except Exception as e:\n",
        "            self.data = self.sample_data.copy()\n",
        "            return f\"❌ Error loading file: {str(e)}\\n🔄 Using sample data instead.\"\n",
        "\n",
        "    def clean_data(self):\n",
        "        \"\"\"Enhanced data cleaning\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\"\n",
        "\n",
        "            original_shape = self.data.shape\n",
        "\n",
        "            # Remove duplicates\n",
        "            self.data = self.data.drop_duplicates()\n",
        "\n",
        "            # Clean text columns - remove HTML entities and extra spaces\n",
        "            text_columns = ['title', 'director', 'country', 'listed_in']\n",
        "            for col in text_columns:\n",
        "                if col in self.data.columns:\n",
        "                    self.data[col] = self.data[col].astype(str)\n",
        "                    self.data[col] = self.data[col].str.replace('&amp;', '&', regex=False)\n",
        "                    self.data[col] = self.data[col].str.replace('&amp;amp;', '&', regex=False)\n",
        "                    self.data[col] = self.data[col].str.strip()\n",
        "                    # Replace 'nan' strings with actual NaN\n",
        "                    self.data[col] = self.data[col].replace('nan', np.nan)\n",
        "\n",
        "            # Convert date_added to datetime with better handling\n",
        "            if 'date_added' in self.data.columns:\n",
        "                self.data['date_added'] = pd.to_datetime(self.data['date_added'], errors='coerce')\n",
        "                # Extract date components\n",
        "                self.data['year_added'] = self.data['date_added'].dt.year\n",
        "                self.data['month_added'] = self.data['date_added'].dt.month\n",
        "\n",
        "            # Clean rating column\n",
        "            if 'rating' in self.data.columns:\n",
        "                self.data['rating'] = self.data['rating'].str.strip()\n",
        "\n",
        "            # Clean release_year column\n",
        "            if 'release_year' in self.data.columns:\n",
        "                self.data['release_year'] = pd.to_numeric(self.data['release_year'], errors='coerce')\n",
        "\n",
        "            return f\"✅ Enhanced data cleaning completed!\\nOriginal: {original_shape} → Cleaned: {self.data.shape}\\n📅 Date columns added\\n🧹 Text cleaned & HTML entities removed\"\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error cleaning data: {str(e)}\"\n",
        "\n",
        "    def create_plot_image(self, fig):\n",
        "        \"\"\"Convert matplotlib figure to image\"\"\"\n",
        "        try:\n",
        "            import tempfile\n",
        "            import os\n",
        "\n",
        "            # Create a temporary file\n",
        "            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')\n",
        "            fig.savefig(temp_file.name, format='png', bbox_inches='tight', dpi=100, facecolor='white')\n",
        "            plt.close(fig)\n",
        "            return temp_file.name\n",
        "        except Exception as e:\n",
        "            plt.close(fig)\n",
        "            return None\n",
        "\n",
        "    def content_distribution_analysis(self):\n",
        "        \"\"\"Analyze content distribution only\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\", None\n",
        "\n",
        "            # Create single plot for content distribution\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "\n",
        "            # Content Distribution Analysis\n",
        "            content_counts = self.data['type'].value_counts()\n",
        "            content_counts.plot(kind='bar', ax=ax, color=['#ff7f7f', '#7fbfff'])\n",
        "            ax.set_title('Content Distribution on Netflix', fontsize=16, pad=20)\n",
        "            ax.set_xlabel('Content Type', fontsize=12)\n",
        "            ax.set_ylabel('Count', fontsize=12)\n",
        "            ax.tick_params(axis='x', rotation=0)\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for i, v in enumerate(content_counts.values):\n",
        "                ax.text(i, v + 0.1, str(v), ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Generate content insights\n",
        "            total = len(self.data)\n",
        "            insights = \"🎬 CONTENT DISTRIBUTION ANALYSIS:\\n\\n\"\n",
        "            for content_type, count in content_counts.items():\n",
        "                percentage = (count / total) * 100\n",
        "                insights += f\"• {content_type}: {count} titles ({percentage:.1f}%)\\n\"\n",
        "\n",
        "            insights += f\"\\n📊 SUMMARY:\\n\"\n",
        "            insights += f\"• Total Content: {total} titles\\n\"\n",
        "            insights += f\"• Content Types: {len(content_counts)} categories\\n\"\n",
        "            if content_counts.iloc[0] > content_counts.iloc[1]:\n",
        "                insights += f\"• {content_counts.index[0]} content dominates the platform\\n\"\n",
        "            else:\n",
        "                insights += f\"• Balanced mix of content types\\n\"\n",
        "\n",
        "            plot_img = self.create_plot_image(fig)\n",
        "            return insights, plot_img\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error in content distribution analysis: {str(e)}\", None\n",
        "\n",
        "    def ratings_distribution_analysis(self):\n",
        "        \"\"\"Analyze ratings distribution only\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\", None\n",
        "\n",
        "            # Create single plot for ratings distribution\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
        "\n",
        "            # Ratings Analysis\n",
        "            rating_counts = self.data['rating'].value_counts().head(10)\n",
        "            rating_counts.plot(kind='bar', ax=ax, color='steelblue')\n",
        "            ax.set_title('Top Content Ratings Distribution', fontsize=16, pad=20)\n",
        "            ax.set_xlabel('Rating', fontsize=12)\n",
        "            ax.set_ylabel('Count', fontsize=12)\n",
        "            ax.tick_params(axis='x', rotation=45)\n",
        "\n",
        "            # Add value labels\n",
        "            for i, v in enumerate(rating_counts.values):\n",
        "                ax.text(i, v + 0.1, str(v), ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Generate ratings insights\n",
        "            insights = \"⭐ RATINGS DISTRIBUTION ANALYSIS:\\n\\n\"\n",
        "            insights += f\"Total unique ratings: {len(self.data['rating'].unique())}\\n\\n\"\n",
        "            insights += \"Top 5 Ratings:\\n\"\n",
        "            for i, (rating, count) in enumerate(rating_counts.head(5).items(), 1):\n",
        "                percentage = (count / len(self.data)) * 100\n",
        "                insights += f\"{i}. {rating}: {count} titles ({percentage:.1f}%)\\n\"\n",
        "\n",
        "            # Add rating category analysis\n",
        "            insights += f\"\\n🔞 RATING CATEGORIES:\\n\"\n",
        "            mature_ratings = ['R', 'TV-MA', 'NC-17']\n",
        "            family_ratings = ['G', 'PG', 'TV-G', 'TV-Y', 'TV-Y7']\n",
        "            teen_ratings = ['PG-13', 'TV-14']\n",
        "\n",
        "            mature_count = sum([self.data['rating'].value_counts().get(rating, 0) for rating in mature_ratings])\n",
        "            family_count = sum([self.data['rating'].value_counts().get(rating, 0) for rating in family_ratings])\n",
        "            teen_count = sum([self.data['rating'].value_counts().get(rating, 0) for rating in teen_ratings])\n",
        "\n",
        "            insights += f\"• Mature Content: {mature_count} titles ({(mature_count/len(self.data)*100):.1f}%)\\n\"\n",
        "            insights += f\"• Family Content: {family_count} titles ({(family_count/len(self.data)*100):.1f}%)\\n\"\n",
        "            insights += f\"• Teen Content: {teen_count} titles ({(teen_count/len(self.data)*100):.1f}%)\\n\"\n",
        "\n",
        "            plot_img = self.create_plot_image(fig)\n",
        "            return insights, plot_img\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error in ratings distribution analysis: {str(e)}\", None\n",
        "\n",
        "    def countries_analysis(self):\n",
        "        \"\"\"Analyze content by countries\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\", None\n",
        "\n",
        "            country_counts = self.data['country'].value_counts().head(10)\n",
        "\n",
        "            # Create horizontal bar plot\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
        "            country_counts.plot(kind='barh', ax=ax, color='green', alpha=0.7)\n",
        "            ax.set_title('Top 10 Countries with Most Netflix Content', fontsize=14, pad=20)\n",
        "            ax.set_xlabel('Number of Titles')\n",
        "            ax.set_ylabel('Country')\n",
        "\n",
        "            # Add value labels\n",
        "            for i, v in enumerate(country_counts.values):\n",
        "                ax.text(v + 0.1, i, str(v), ha='left', va='center')\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Generate insights\n",
        "            insights = \"🌍 COUNTRIES ANALYSIS:\\n\\n\"\n",
        "            insights += f\"Content from {len(self.data['country'].unique())} different countries\\n\\n\"\n",
        "            insights += \"Top 5 Countries:\\n\"\n",
        "            for i, (country, count) in enumerate(country_counts.head(5).items(), 1):\n",
        "                percentage = (count / len(self.data)) * 100\n",
        "                insights += f\"{i}. {country}: {count} titles ({percentage:.1f}%)\\n\"\n",
        "\n",
        "            plot_img = self.create_plot_image(fig)\n",
        "            return insights, plot_img\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error in countries analysis: {str(e)}\", None\n",
        "\n",
        "    def directors_analysis(self):\n",
        "        \"\"\"Analyze top 10 directors\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\", None\n",
        "\n",
        "            directors = self.data['director'].value_counts().head(10)  # CHANGED: from 8 to 10\n",
        "\n",
        "            # Create horizontal bar plot\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(10, 8))  # CHANGED: increased height for 10 directors\n",
        "            directors.plot(kind='barh', ax=ax, color='orange', alpha=0.7)\n",
        "            ax.set_title('Top 10 Directors with Most Netflix Content', fontsize=14, pad=20)  # CHANGED: title\n",
        "            ax.set_xlabel('Number of Titles')\n",
        "            ax.set_ylabel('Director')\n",
        "\n",
        "            # Add value labels\n",
        "            for i, v in enumerate(directors.values):\n",
        "                ax.text(v + 0.1, i, str(v), ha='left', va='center')\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Generate insights\n",
        "            insights = \"🎭 DIRECTORS ANALYSIS:\\n\\n\"\n",
        "            insights += f\"Top 10 Directors by Content Volume:\\n\"  # CHANGED: from \"Top Directors\" to \"Top 10 Directors\"\n",
        "            for i, (director, count) in enumerate(directors.items(), 1):\n",
        "                insights += f\"{i}. {director}: {count} titles\\n\"\n",
        "\n",
        "            plot_img = self.create_plot_image(fig)\n",
        "            return insights, plot_img\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error in directors analysis: {str(e)}\", None\n",
        "\n",
        "    def genres_analysis(self):\n",
        "        \"\"\"Analyze content by genres with enhanced features\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\", None\n",
        "\n",
        "            # Extract individual genres from listed_in column\n",
        "            all_genres = []\n",
        "            genre_counts_per_content = []  # NEW: Count genres per content\n",
        "\n",
        "            for genres_list in self.data['listed_in'].dropna():\n",
        "                # Split by comma and clean up\n",
        "                genres = [genre.strip() for genre in genres_list.split(',')]\n",
        "                all_genres.extend(genres)\n",
        "                genre_counts_per_content.append(len(genres))  # NEW: Count genres per content\n",
        "\n",
        "            # Count genre frequencies\n",
        "            genre_counts = pd.Series(all_genres).value_counts().head(12)\n",
        "\n",
        "            # NEW: Calculate average genres per content\n",
        "            avg_genres_per_content = np.mean(genre_counts_per_content)\n",
        "\n",
        "            # NEW: Find top genre\n",
        "            top_genre = genre_counts.index[0] if len(genre_counts) > 0 else \"Unknown\"\n",
        "\n",
        "            # Create horizontal bar plot\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
        "            genre_counts.plot(kind='barh', ax=ax, color='purple', alpha=0.7)\n",
        "            ax.set_title('Top 12 Most Popular Genres on Netflix', fontsize=14, pad=20)\n",
        "            ax.set_xlabel('Number of Titles')\n",
        "            ax.set_ylabel('Genre')\n",
        "\n",
        "            # Add value labels\n",
        "            for i, v in enumerate(genre_counts.values):\n",
        "                ax.text(v + 0.1, i, str(v), ha='left', va='center')\n",
        "\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Generate insights - ENHANCED\n",
        "            insights = \"🎭 GENRES ANALYSIS:\\n\\n\"\n",
        "            insights += f\"📊 TOP GENRE: {top_genre} ({genre_counts.iloc[0]} titles)\\n\"  # NEW\n",
        "            insights += f\"📈 Average genres per content: {avg_genres_per_content:.1f}\\n\"  # NEW\n",
        "            insights += f\"Total unique genres: {len(pd.Series(all_genres).unique())}\\n\"\n",
        "            insights += f\"Total genre mentions: {len(all_genres)}\\n\\n\"\n",
        "\n",
        "            # NEW: Genre distribution stats\n",
        "            insights += f\"🔢 GENRE COUNT DISTRIBUTION:\\n\"\n",
        "            genre_count_dist = pd.Series(genre_counts_per_content).value_counts().sort_index()\n",
        "            for count, freq in genre_count_dist.head(5).items():\n",
        "                insights += f\"• {count} genre(s): {freq} titles\\n\"\n",
        "            insights += \"\\n\"\n",
        "\n",
        "            insights += \"Top 10 Most Popular Genres:\\n\"\n",
        "            for i, (genre, count) in enumerate(genre_counts.head(10).items(), 1):\n",
        "                percentage = (count / len(self.data)) * 100\n",
        "                insights += f\"{i}. {genre}: {count} titles ({percentage:.1f}%)\\n\"\n",
        "\n",
        "            plot_img = self.create_plot_image(fig)\n",
        "            return insights, plot_img\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error in genres analysis: {str(e)}\", None\n",
        "\n",
        "    def get_movie_details(self, movie_title):\n",
        "        \"\"\"NEW FEATURE: Get detailed information about a specific movie including genre count and duration extraction\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\"\n",
        "\n",
        "            # Search for the movie (case insensitive, partial match)\n",
        "            movie_matches = self.data[self.data['title'].str.contains(movie_title, case=False, na=False)]\n",
        "\n",
        "            if movie_matches.empty:\n",
        "                # Show available movie titles for suggestion\n",
        "                available_movies = self.data['title'].head(10).tolist()\n",
        "                return f\"❌ Movie '{movie_title}' not found!\\n\\n🎬 Available movies to try:\\n\" + \"\\n\".join([f\"• {movie}\" for movie in available_movies])\n",
        "\n",
        "            # Get the first match\n",
        "            movie = movie_matches.iloc[0]\n",
        "\n",
        "            # Extract duration in minutes\n",
        "            duration_text = str(movie['duration']) if pd.notna(movie['duration']) else \"Unknown\"\n",
        "            duration_minutes = 0\n",
        "            duration_info = \"Duration info not available\"\n",
        "\n",
        "            if 'min' in duration_text:\n",
        "                try:\n",
        "                    duration_minutes = int(duration_text.split(' ')[0])\n",
        "                    duration_info = f\"{duration_minutes} minutes\"\n",
        "                except:\n",
        "                    duration_info = duration_text\n",
        "            elif 'Season' in duration_text:\n",
        "                try:\n",
        "                    seasons = int(duration_text.split(' ')[0])\n",
        "                    duration_info = f\"{seasons} Season(s) - Estimated {seasons * 10} episodes\"\n",
        "                except:\n",
        "                    duration_info = duration_text\n",
        "            else:\n",
        "                duration_info = duration_text\n",
        "\n",
        "            # Count genres for this movie\n",
        "            genres_list = str(movie['listed_in']) if pd.notna(movie['listed_in']) else \"\"\n",
        "            if genres_list and genres_list != 'nan':\n",
        "                genres = [genre.strip() for genre in genres_list.split(',')]\n",
        "                genre_count = len(genres)\n",
        "            else:\n",
        "                genres = []\n",
        "                genre_count = 0\n",
        "\n",
        "            # Calculate content age\n",
        "            current_year = datetime.now().year\n",
        "            content_age = current_year - movie['release_year'] if pd.notna(movie['release_year']) else \"Unknown\"\n",
        "\n",
        "            # Generate detailed report\n",
        "            result = f\"🎬 DETAILED MOVIE INFORMATION\\n\"\n",
        "            result += \"=\" * 50 + \"\\n\\n\"\n",
        "\n",
        "            result += f\"📽️ TITLE: {movie['title']}\\n\"\n",
        "            result += f\"🎭 TYPE: {movie['type']}\\n\"\n",
        "            result += f\"🎬 DIRECTOR: {movie['director'] if pd.notna(movie['director']) else 'Unknown'}\\n\"\n",
        "            result += f\"🌍 COUNTRY: {movie['country'] if pd.notna(movie['country']) else 'Unknown'}\\n\"\n",
        "            result += f\"📅 RELEASE YEAR: {movie['release_year'] if pd.notna(movie['release_year']) else 'Unknown'}\\n\"\n",
        "            result += f\"🔞 RATING: {movie['rating'] if pd.notna(movie['rating']) else 'Unknown'}\\n\\n\"\n",
        "\n",
        "            # NEW FEATURES - Duration and Genre Analysis\n",
        "            result += f\"⏱️ DURATION ANALYSIS:\\n\"\n",
        "            result += f\"• Original Duration: {duration_text}\\n\"\n",
        "            result += f\"• Extracted Duration: {duration_info}\\n\"\n",
        "            if duration_minutes > 0:\n",
        "                result += f\"• Duration in Minutes: {duration_minutes} min\\n\"\n",
        "                result += f\"• Duration Category: \"\n",
        "                if duration_minutes < 90:\n",
        "                    result += \"Short Film/Episode\\n\"\n",
        "                elif duration_minutes < 120:\n",
        "                    result += \"Standard Length\\n\"\n",
        "                elif duration_minutes < 180:\n",
        "                    result += \"Long Feature\\n\"\n",
        "                else:\n",
        "                    result += \"Epic Length\\n\"\n",
        "            result += \"\\n\"\n",
        "\n",
        "            result += f\"🎭 GENRE ANALYSIS:\\n\"\n",
        "            result += f\"• Total Genre Count: {genre_count}\\n\"\n",
        "            if genres:\n",
        "                result += f\"• All Genres: {', '.join(genres)}\\n\"\n",
        "                result += f\"• Primary Genre: {genres[0]}\\n\"\n",
        "                if len(genres) > 1:\n",
        "                    result += f\"• Secondary Genres: {', '.join(genres[1:])}\\n\"\n",
        "\n",
        "                # Genre category analysis\n",
        "                result += f\"\\n🏷️ GENRE CATEGORIES:\\n\"\n",
        "                action_genres = ['Action', 'Adventure', 'Thrillers']\n",
        "                drama_genres = ['Dramas', 'Romantic Movies']\n",
        "                comedy_genres = ['Comedies', 'Romantic Comedies']\n",
        "                family_genres = ['Children & Family Movies', 'Family']\n",
        "\n",
        "                for category, keywords in [('Action/Adventure', action_genres),\n",
        "                                         ('Drama', drama_genres),\n",
        "                                         ('Comedy', comedy_genres),\n",
        "                                         ('Family', family_genres)]:\n",
        "                    if any(keyword in genre for keyword in keywords for genre in genres):\n",
        "                        result += f\"• {category}: ✅\\n\"\n",
        "            else:\n",
        "                result += f\"• No genre information available\\n\"\n",
        "\n",
        "            result += f\"\\n📊 ADDITIONAL METRICS:\\n\"\n",
        "            result += f\"• Content Age: {content_age} years old\\n\"\n",
        "            result += f\"• Date Added: {movie['date_added'].strftime('%B %d, %Y') if pd.notna(movie['date_added']) else 'Unknown'}\\n\"\n",
        "\n",
        "            # Similar content analysis\n",
        "            if genre_count > 0:\n",
        "                similar_count = 0\n",
        "                for _, other_movie in self.data.iterrows():\n",
        "                    if other_movie['title'] != movie['title']:\n",
        "                        other_genres = str(other_movie['listed_in']) if pd.notna(other_movie['listed_in']) else \"\"\n",
        "                        if other_genres:\n",
        "                            other_genre_list = [g.strip() for g in other_genres.split(',')]\n",
        "                            # Check for genre overlap\n",
        "                            if any(genre in other_genre_list for genre in genres):\n",
        "                                similar_count += 1\n",
        "\n",
        "                result += f\"• Similar Genre Content: ~{similar_count} titles with overlapping genres\\n\"\n",
        "\n",
        "            result += f\"\\n🎯 CONTENT SUMMARY:\\n\"\n",
        "            if duration_minutes > 0 and genre_count > 0:\n",
        "                result += f\"• This {duration_info} {movie['type'].lower()} spans {genre_count} genre(s)\\n\"\n",
        "            result += f\"• Primary focus: {genres[0] if genres else 'Unknown genre'}\\n\"\n",
        "            if movie['type'] == 'Movie' and duration_minutes > 0:\n",
        "                result += f\"• Watch time commitment: {duration_minutes // 60}h {duration_minutes % 60}m\\n\"\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error getting movie details: {str(e)}\"\n",
        "\n",
        "    def prepare_ml_features(self):\n",
        "        \"\"\"Prepare features for ML models\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\"\n",
        "\n",
        "            # Create a copy for ML processing\n",
        "            ml_data = self.data.copy()\n",
        "\n",
        "            # Extract duration in minutes for movies, seasons for TV shows\n",
        "            ml_data['duration_numeric'] = 0\n",
        "            for idx, row in ml_data.iterrows():\n",
        "                if pd.notna(row['duration']):\n",
        "                    if 'min' in str(row['duration']):\n",
        "                        ml_data.loc[idx, 'duration_numeric'] = int(str(row['duration']).split(' ')[0])\n",
        "                    elif 'Season' in str(row['duration']):\n",
        "                        ml_data.loc[idx, 'duration_numeric'] = int(str(row['duration']).split(' ')[0]) * 60  # Convert seasons to minutes equivalent\n",
        "\n",
        "            # Create age of content feature\n",
        "            current_year = datetime.now().year\n",
        "            ml_data['content_age'] = current_year - ml_data['release_year']\n",
        "\n",
        "            # Extract primary genre\n",
        "            ml_data['primary_genre'] = ml_data['listed_in'].str.split(',').str[0]\n",
        "\n",
        "            # Create success score based on multiple factors (synthetic for demo)\n",
        "            np.random.seed(42)\n",
        "            ml_data['success_score'] = (\n",
        "                np.random.normal(0.5, 0.2, len(ml_data)) +\n",
        "                (ml_data['duration_numeric'] / 200) * 0.3 +\n",
        "                (2024 - ml_data['release_year']) * 0.01\n",
        "            )\n",
        "            ml_data['success_score'] = np.clip(ml_data['success_score'], 0, 1)\n",
        "\n",
        "            # Create success categories\n",
        "            ml_data['success_category'] = pd.cut(ml_data['success_score'],\n",
        "                                               bins=[0, 0.3, 0.7, 1.0],\n",
        "                                               labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "            return ml_data\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error preparing ML features: {str(e)}\"\n",
        "\n",
        "    def train_success_prediction_model(self):\n",
        "        \"\"\"Train content success prediction model\"\"\"\n",
        "        try:\n",
        "            ml_data = self.prepare_ml_features()\n",
        "            if isinstance(ml_data, str):\n",
        "                return ml_data\n",
        "\n",
        "            # Select features for training\n",
        "            feature_columns = ['release_year', 'duration_numeric', 'content_age']\n",
        "            categorical_features = ['type', 'country', 'rating', 'primary_genre']\n",
        "\n",
        "            # Prepare features\n",
        "            X = ml_data[feature_columns].copy()\n",
        "\n",
        "            # Encode categorical variables\n",
        "            for col in categorical_features:\n",
        "                if col in ml_data.columns:\n",
        "                    le = LabelEncoder()\n",
        "                    ml_data[col] = ml_data[col].fillna('Unknown')\n",
        "                    X[col + '_encoded'] = le.fit_transform(ml_data[col])\n",
        "                    self.label_encoders[col] = le\n",
        "\n",
        "            # Target variable\n",
        "            y = ml_data['success_category'].dropna()\n",
        "            X = X.loc[y.index]\n",
        "\n",
        "            # Split data\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "            # Scale features\n",
        "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "            X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "            # Train model\n",
        "            self.ml_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "            self.ml_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "            # Make predictions\n",
        "            y_pred = self.ml_model.predict(X_test_scaled)\n",
        "            accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "            # Feature importance\n",
        "            feature_names = X.columns\n",
        "            importances = self.ml_model.feature_importances_\n",
        "\n",
        "            # Create feature importance plot\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
        "            indices = np.argsort(importances)[::-1][:10]\n",
        "            ax.bar(range(len(indices)), importances[indices])\n",
        "            ax.set_title('Top 10 Feature Importances for Content Success Prediction')\n",
        "            ax.set_xlabel('Features')\n",
        "            ax.set_ylabel('Importance')\n",
        "            ax.set_xticks(range(len(indices)))\n",
        "            ax.set_xticklabels([feature_names[i] for i in indices], rotation=45)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            results = f\"🤖 CONTENT SUCCESS PREDICTION MODEL\\n\\n\"\n",
        "            results += f\"✅ Model trained successfully!\\n\"\n",
        "            results += f\"📊 Model Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)\\n\"\n",
        "            results += f\"📈 Training Samples: {len(X_train)}\\n\"\n",
        "            results += f\"🧪 Test Samples: {len(X_test)}\\n\\n\"\n",
        "            results += f\"🎯 FEATURE IMPORTANCE:\\n\"\n",
        "\n",
        "            for i, idx in enumerate(indices[:5]):\n",
        "                results += f\"{i+1}. {feature_names[idx]}: {importances[idx]:.3f}\\n\"\n",
        "\n",
        "            results += f\"\\n📝 Model can predict if content will have Low/Medium/High success based on:\\n\"\n",
        "            results += f\"• Content metadata (year, duration, genre)\\n\"\n",
        "            results += f\"• Production details (country, rating)\\n\"\n",
        "            results += f\"• Content age and type\\n\"\n",
        "\n",
        "            plot_img = self.create_plot_image(fig)\n",
        "            return results, plot_img\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error training model: {str(e)}\", None\n",
        "\n",
        "    def predict_content_success(self, content_type, country, rating, genre, release_year, duration):\n",
        "        \"\"\"Predict success for new content\"\"\"\n",
        "        try:\n",
        "            if self.ml_model is None:\n",
        "                return \"❌ Please train the model first!\"\n",
        "\n",
        "            # Prepare input data\n",
        "            input_data = pd.DataFrame({\n",
        "                'release_year': [release_year],\n",
        "                'duration_numeric': [duration],\n",
        "                'content_age': [datetime.now().year - release_year]\n",
        "            })\n",
        "\n",
        "            # Encode categorical features\n",
        "            for col, value in [('type', content_type), ('country', country),\n",
        "                              ('rating', rating), ('primary_genre', genre)]:\n",
        "                if col in self.label_encoders:\n",
        "                    try:\n",
        "                        encoded_value = self.label_encoders[col].transform([value])[0]\n",
        "                    except ValueError:\n",
        "                        # Handle unseen categories\n",
        "                        encoded_value = 0\n",
        "                    input_data[col + '_encoded'] = encoded_value\n",
        "\n",
        "            # Scale features\n",
        "            input_scaled = self.scaler.transform(input_data)\n",
        "\n",
        "            # Make prediction\n",
        "            prediction = self.ml_model.predict(input_scaled)[0]\n",
        "            probability = self.ml_model.predict_proba(input_scaled)[0]\n",
        "\n",
        "            # Get class probabilities\n",
        "            classes = self.ml_model.classes_\n",
        "            prob_dict = dict(zip(classes, probability))\n",
        "\n",
        "            result = f\"🎯 CONTENT SUCCESS PREDICTION\\n\\n\"\n",
        "            result += f\"📹 Content: {content_type} from {country}\\n\"\n",
        "            result += f\"🎬 Genre: {genre} | Rating: {rating}\\n\"\n",
        "            result += f\"📅 Release Year: {release_year} | Duration: {duration} min\\n\\n\"\n",
        "            result += f\"🔮 PREDICTED SUCCESS: {prediction}\\n\\n\"\n",
        "            result += f\"📊 SUCCESS PROBABILITIES:\\n\"\n",
        "            for class_name, prob in prob_dict.items():\n",
        "                result += f\"• {class_name}: {prob:.1%}\\n\"\n",
        "\n",
        "            # Add recommendations\n",
        "            if prediction == 'High':\n",
        "                result += f\"\\n✅ RECOMMENDATION: This content has strong success potential!\"\n",
        "            elif prediction == 'Medium':\n",
        "                result += f\"\\n⚠️ RECOMMENDATION: Moderate success expected. Consider optimization.\"\n",
        "            else:\n",
        "                result += f\"\\n❌ RECOMMENDATION: High risk. Review content strategy.\"\n",
        "\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error making prediction: {str(e)}\"\n",
        "\n",
        "    def build_recommendation_system(self):\n",
        "        \"\"\"Build content-based recommendation system focused on genres\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\"\n",
        "\n",
        "            # Prepare content features for similarity\n",
        "            content_data = self.data.copy()\n",
        "\n",
        "            # Create feature text with HEAVY emphasis on genres\n",
        "            content_data['features'] = (\n",
        "                # Give genres 5x weight by repeating them\n",
        "                (content_data['listed_in'].fillna('') + ' ') * 5 +\n",
        "                # Add type 2x weight (Movie/TV Show similarity)\n",
        "                (content_data['type'].fillna('') + ' ') * 2 +\n",
        "                # Give rating some weight for age-appropriate content\n",
        "                (content_data['rating'].fillna('') + ' ') * 2 +\n",
        "                # Minimal weight to country and director\n",
        "                content_data['country'].fillna('') + ' ' +\n",
        "                content_data['director'].fillna('')\n",
        "            )\n",
        "\n",
        "            # Create TF-IDF vectors with better parameters for genre focus\n",
        "            self.tfidf_vectorizer = TfidfVectorizer(\n",
        "                max_features=2000,\n",
        "                stop_words='english',\n",
        "                ngram_range=(1, 2),  # Include bigrams for better genre matching\n",
        "                min_df=1,  # Don't ignore rare genre combinations\n",
        "                max_df=0.95  # Ignore overly common terms\n",
        "            )\n",
        "            self.content_features = self.tfidf_vectorizer.fit_transform(content_data['features'])\n",
        "\n",
        "            results = f\"🎯 GENRE-FOCUSED RECOMMENDATION SYSTEM BUILT\\n\\n\"\n",
        "            results += f\"✅ Enhanced content-based filtering model created!\\n\"\n",
        "            results += f\"📊 Total content items: {len(content_data)}\\n\"\n",
        "            results += f\"🔢 Feature dimensions: {self.content_features.shape[1]}\\n\\n\"\n",
        "            results += f\"🎬 RECOMMENDATION PRIORITY (BY WEIGHT):\\n\"\n",
        "            results += f\"1. 🎭 GENRES & CATEGORIES (5x weight) ⭐⭐⭐⭐⭐\\n\"\n",
        "            results += f\"2. 📺 Content Type (2x weight) ⭐⭐\\n\"\n",
        "            results += f\"3. 🔞 Content Rating (2x weight) ⭐⭐\\n\"\n",
        "            results += f\"4. 🌍 Country (1x weight) ⭐\\n\"\n",
        "            results += f\"5. 🎬 Director (1x weight) ⭐\\n\\n\"\n",
        "            results += f\"🔍 IMPROVED MATCHING:\\n\"\n",
        "            results += f\"• Horror movies → Other horror content\\n\"\n",
        "            results += f\"• Comedy → Similar comedy styles\\n\"\n",
        "            results += f\"• Drama → Character-driven dramas\\n\"\n",
        "            results += f\"• Action → High-energy action content\\n\\n\"\n",
        "            results += f\"🚀 System ready! Genre-based recommendations prioritized.\"\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error building recommendation system: {str(e)}\"\n",
        "\n",
        "    def get_recommendations(self, title, num_recommendations=5):\n",
        "        \"\"\"Get genre-focused recommendations for a specific title\"\"\"\n",
        "        try:\n",
        "            if self.content_features is None:\n",
        "                return \"❌ Please build the recommendation system first!\"\n",
        "\n",
        "            # Find the title in dataset\n",
        "            title_matches = self.data[self.data['title'].str.contains(title, case=False, na=False)]\n",
        "\n",
        "            if title_matches.empty:\n",
        "                return f\"❌ Title '{title}' not found! Try: {', '.join(self.data['title'].head(5))}\"\n",
        "\n",
        "            # Get the index of the first match\n",
        "            title_idx = title_matches.index[0]\n",
        "            title_info = self.data.iloc[title_idx]\n",
        "\n",
        "            # Calculate similarity scores\n",
        "            similarity_scores = cosine_similarity(\n",
        "                self.content_features[title_idx:title_idx+1],\n",
        "                self.content_features\n",
        "            ).flatten()\n",
        "\n",
        "            # Get top similar content (excluding the same title)\n",
        "            similar_indices = similarity_scores.argsort()[::-1][1:num_recommendations+1]\n",
        "\n",
        "            # Extract primary genre for better context\n",
        "            primary_genre = title_info['listed_in'].split(',')[0].strip() if pd.notna(title_info['listed_in']) else 'Unknown'\n",
        "\n",
        "            recommendations = f\"🎯 GENRE-FOCUSED RECOMMENDATIONS FOR: {title_info['title']}\\n\\n\"\n",
        "            recommendations += f\"📹 Original: {title_info['type']} | 🎭 Primary Genre: {primary_genre}\\n\"\n",
        "            recommendations += f\"🌍 Country: {title_info['country']} | 🔞 Rating: {title_info['rating']}\\n\\n\"\n",
        "            recommendations += f\"🔍 TOP {num_recommendations} SIMILAR CONTENT (Genre Priority):\\n\\n\"\n",
        "\n",
        "            for i, idx in enumerate(similar_indices, 1):\n",
        "                similar_content = self.data.iloc[idx]\n",
        "                similarity_score = similarity_scores[idx]\n",
        "                similar_primary_genre = similar_content['listed_in'].split(',')[0].strip() if pd.notna(similar_content['listed_in']) else 'Unknown'\n",
        "\n",
        "                # Add genre match indicator\n",
        "                genre_match = \"🎯\" if primary_genre.lower() in similar_content['listed_in'].lower() else \"📍\"\n",
        "\n",
        "                recommendations += f\"{i}. {genre_match} {similar_content['title']}\\n\"\n",
        "                recommendations += f\"   📊 Similarity: {similarity_score:.3f} ({similarity_score*100:.1f}%)\\n\"\n",
        "                recommendations += f\"   🎭 Primary Genre: {similar_primary_genre}\\n\"\n",
        "                recommendations += f\"   📋 All Genres: {similar_content['listed_in']}\\n\"\n",
        "                recommendations += f\"   🌍 {similar_content['country']} | 📺 {similar_content['type']} | 🔞 {similar_content['rating']}\\n\\n\"\n",
        "\n",
        "            # Add genre analysis\n",
        "            recommendations += f\"🎭 GENRE MATCHING ANALYSIS:\\n\"\n",
        "            genre_matches = 0\n",
        "            for idx in similar_indices:\n",
        "                similar_content = self.data.iloc[idx]\n",
        "                if primary_genre.lower() in similar_content['listed_in'].lower():\n",
        "                    genre_matches += 1\n",
        "\n",
        "            match_percentage = (genre_matches / len(similar_indices)) * 100\n",
        "            recommendations += f\"• Genre Match Rate: {genre_matches}/{len(similar_indices)} ({match_percentage:.0f}%)\\n\"\n",
        "            recommendations += f\"• Primary Genre: {primary_genre}\\n\"\n",
        "            recommendations += f\"🎯 = Exact genre match | 📍 = Related content\\n\"\n",
        "\n",
        "            return recommendations\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error getting recommendations: {str(e)}\"\n",
        "\n",
        "    def create_dashboard_summary(self):\n",
        "        \"\"\"Create a comprehensive dashboard summary\"\"\"\n",
        "        try:\n",
        "            if self.data is None:\n",
        "                return \"❌ No data loaded!\"\n",
        "\n",
        "            summary = \"📊 NETFLIX DATA ANALYSIS SUMMARY\\n\"\n",
        "            summary += \"=\" * 50 + \"\\n\\n\"\n",
        "\n",
        "            # Basic stats\n",
        "            summary += f\"📈 DATASET OVERVIEW:\\n\"\n",
        "            summary += f\"• Total Records: {len(self.data):,}\\n\"\n",
        "            summary += f\"• Total Columns: {len(self.data.columns)}\\n\"\n",
        "            if 'date_added' in self.data.columns and not self.data['date_added'].isna().all():\n",
        "                summary += f\"• Date Range: {self.data['date_added'].min().strftime('%Y-%m-%d')} to {self.data['date_added'].max().strftime('%Y-%m-%d')}\\n\"\n",
        "            summary += \"\\n\"\n",
        "\n",
        "            # Content breakdown\n",
        "            if 'type' in self.data.columns:\n",
        "                content_counts = self.data['type'].value_counts()\n",
        "                summary += f\"🎬 CONTENT BREAKDOWN:\\n\"\n",
        "                for content_type, count in content_counts.items():\n",
        "                    percentage = (count / len(self.data)) * 100\n",
        "                    summary += f\"• {content_type}: {count:,} ({percentage:.1f}%)\\n\"\n",
        "                summary += \"\\n\"\n",
        "\n",
        "            # Top categories\n",
        "            summary += f\"🌟 TOP CATEGORIES:\\n\"\n",
        "            if 'rating' in self.data.columns:\n",
        "                summary += f\"• Most Popular Rating: {self.data['rating'].mode().iloc[0]}\\n\"\n",
        "            if 'country' in self.data.columns:\n",
        "                summary += f\"• Top Country: {self.data['country'].mode().iloc[0]}\\n\"\n",
        "            if 'year_added' in self.data.columns and not self.data['year_added'].isna().all():\n",
        "                summary += f\"• Most Active Year: {int(self.data['year_added'].mode().iloc[0])}\\n\"\n",
        "            summary += \"\\n\"\n",
        "\n",
        "            # Diversity metrics\n",
        "            summary += f\"🌍 DIVERSITY METRICS:\\n\"\n",
        "            if 'country' in self.data.columns:\n",
        "                summary += f\"• Unique Countries: {self.data['country'].nunique()}\\n\"\n",
        "            if 'director' in self.data.columns:\n",
        "                summary += f\"• Unique Directors: {self.data['director'].nunique()}\\n\"\n",
        "            if 'rating' in self.data.columns:\n",
        "                summary += f\"• Unique Ratings: {self.data['rating'].nunique()}\\n\"\n",
        "            if 'listed_in' in self.data.columns:\n",
        "                summary += f\"• Genre Categories: {self.data['listed_in'].nunique()}\\n\"\n",
        "\n",
        "            return summary\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"❌ Error creating summary: {str(e)}\"\n",
        "\n",
        "# Initialize the analyzer\n",
        "analyzer = NetflixAnalyzer()\n",
        "\n",
        "# Create improved Gradio interface with separate buttons\n",
        "def create_interface():\n",
        "    with gr.Blocks(title=\"Netflix Data Analysis Dashboard\", theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "        gr.Markdown(\"# 🎬 Netflix Data Analysis Dashboard\")\n",
        "        gr.Markdown(\"Interactive analysis of Netflix content data with enhanced genre and director analysis\")\n",
        "\n",
        "        with gr.Tab(\"📊 Data Overview\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    file_input = gr.File(label=\"Upload Netflix CSV Dataset (Optional)\", file_types=[\".csv\"])\n",
        "                    with gr.Row():\n",
        "                        load_btn = gr.Button(\"Load Data\", variant=\"primary\")\n",
        "                        clean_btn = gr.Button(\"Clean Data\", variant=\"secondary\")\n",
        "                    load_output = gr.Textbox(label=\"Status\", lines=3, max_lines=10, show_label=True, container=True)\n",
        "\n",
        "                with gr.Column():\n",
        "                    get_summary_btn = gr.Button(\"Generate Summary Report\", variant=\"primary\")\n",
        "                    summary_output = gr.Textbox(label=\"Dataset Summary\", lines=25, max_lines=50, show_label=True, container=True)\n",
        "\n",
        "            # Sample Data Table Section\n",
        "            gr.Markdown(\"## 📋 Sample Data Overview\")\n",
        "            sample_table_btn = gr.Button(\"🔍 View Sample Data Table\", variant=\"secondary\")\n",
        "            sample_table_output = gr.HTML(label=\"Sample Data Table\")\n",
        "\n",
        "        with gr.Tab(\"📈 Content & Rating Analysis\"):\n",
        "            gr.Markdown(\"## 📊 Content Distribution & Rating Analysis\")\n",
        "            gr.Markdown(\"**Analyze content types and ratings separately with dedicated buttons**\")\n",
        "\n",
        "            # Two separate buttons in one row\n",
        "            with gr.Row():\n",
        "                content_dist_btn = gr.Button(\"🎬 Analyze Content Distribution\", variant=\"primary\", size=\"lg\")\n",
        "                ratings_dist_btn = gr.Button(\"⭐ Analyze Ratings Distribution\", variant=\"secondary\", size=\"lg\")\n",
        "\n",
        "            # Two columns for separate outputs\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    gr.Markdown(\"### 🎬 Content Distribution Results\")\n",
        "                    content_insights = gr.Textbox(label=\"Content Distribution Analysis\", lines=15, max_lines=25, show_label=True, container=True)\n",
        "                    content_plot = gr.Image(label=\"Content Distribution Chart\", show_label=True)\n",
        "\n",
        "                with gr.Column():\n",
        "                    gr.Markdown(\"### ⭐ Ratings Distribution Results\")\n",
        "                    ratings_insights = gr.Textbox(label=\"Ratings Distribution Analysis\", lines=15, max_lines=25, show_label=True, container=True)\n",
        "                    ratings_plot = gr.Image(label=\"Ratings Distribution Chart\", show_label=True)\n",
        "\n",
        "        with gr.Tab(\"🌍 Countries Analysis\"):\n",
        "            gr.Markdown(\"## 🌍 Analyze Content by Countries\")\n",
        "            countries_btn = gr.Button(\"🚀 Analyze Countries Distribution\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    countries_insights = gr.Textbox(label=\"Countries Analysis Insights\", lines=15, max_lines=25, show_label=True, container=True)\n",
        "                with gr.Column():\n",
        "                    countries_plot = gr.Image(label=\"Countries Distribution Chart\", show_label=True)\n",
        "\n",
        "        with gr.Tab(\"🎭 Directors Analysis (Enhanced)\"):\n",
        "            gr.Markdown(\"## 🎭 Analyze Top 10 Directors\")\n",
        "            gr.Markdown(\"**Enhanced analysis showing top 10 directors with most Netflix content**\")\n",
        "            directors_btn = gr.Button(\"🚀 Analyze Top 10 Directors Distribution\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    directors_insights = gr.Textbox(label=\"Top 10 Directors Analysis Insights\", lines=15, max_lines=25, show_label=True, container=True)\n",
        "                with gr.Column():\n",
        "                    directors_plot = gr.Image(label=\"Top 10 Directors Distribution Chart\", show_label=True)\n",
        "\n",
        "        with gr.Tab(\"🎬 Genres Analysis (Enhanced)\"):\n",
        "            gr.Markdown(\"## 🎬 Enhanced Genres Analysis\")\n",
        "            gr.Markdown(\"**Advanced genre analysis with genre count per content, top genre identification, and distribution statistics**\")\n",
        "            genres_btn = gr.Button(\"🚀 Analyze Enhanced Genres Distribution\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    genres_insights = gr.Textbox(label=\"Enhanced Genres Analysis Insights\", lines=20, max_lines=30, show_label=True, container=True)\n",
        "                with gr.Column():\n",
        "                    genres_plot = gr.Image(label=\"Enhanced Genres Distribution Chart\", show_label=True)\n",
        "\n",
        "        with gr.Tab(\"🔍 Movie Details Lookup (NEW)\"):\n",
        "            gr.Markdown(\"## 🔍 Movie Details Lookup with Genre Count & Duration Analysis\")\n",
        "            gr.Markdown(\"**NEW FEATURE: Get detailed information about any movie including genre count and duration extraction**\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    movie_title_input = gr.Textbox(\n",
        "                        label=\"Enter Movie/Show Title\",\n",
        "                        placeholder=\"e.g., Bird Box, Stranger Things, Roma, The Irishman\",\n",
        "                        lines=1\n",
        "                    )\n",
        "                    get_movie_details_btn = gr.Button(\"🎬 Get Movie Details\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                with gr.Column():\n",
        "                    gr.Markdown(\"### 📝 What This Feature Does:\")\n",
        "                    gr.Markdown(\"• **Genre Count**: Counts total genres per movie\")\n",
        "                    gr.Markdown(\"• **Duration Extraction**: Extracts duration in minutes\")\n",
        "                    gr.Markdown(\"• **Content Analysis**: Detailed movie information\")\n",
        "                    gr.Markdown(\"• **Similar Content**: Finds related movies\")\n",
        "\n",
        "            movie_details_output = gr.Textbox(\n",
        "                label=\"Movie Details & Analysis\",\n",
        "                lines=25,\n",
        "                max_lines=40,\n",
        "                show_label=True,\n",
        "                container=True\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"🤖 ML: Success Prediction\"):\n",
        "            gr.Markdown(\"## 🤖 Machine Learning: Content Success Prediction\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    train_model_btn = gr.Button(\"🚀 Train Success Prediction Model\", variant=\"primary\", size=\"lg\")\n",
        "                    ml_results = gr.Textbox(label=\"Model Training Results\", lines=20, max_lines=30, show_label=True, container=True)\n",
        "                with gr.Column():\n",
        "                    ml_plot = gr.Image(label=\"Feature Importance Chart\", show_label=True)\n",
        "\n",
        "            gr.Markdown(\"### 🔮 Predict Success for New Content\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    pred_type = gr.Dropdown([\"Movie\", \"TV Show\"], label=\"Content Type\", value=\"Movie\")\n",
        "                    pred_country = gr.Dropdown([\"United States\", \"United Kingdom\", \"Canada\", \"India\", \"Spain\", \"France\"],\n",
        "                                             label=\"Country\", value=\"United States\")\n",
        "                    pred_rating = gr.Dropdown([\"PG\", \"PG-13\", \"R\", \"TV-MA\", \"TV-14\", \"TV-PG\"],\n",
        "                                            label=\"Rating\", value=\"PG-13\")\n",
        "                with gr.Column():\n",
        "                    pred_genre = gr.Dropdown([\"Action & Adventure\", \"Dramas\", \"Comedies\", \"Horror Movies\", \"Documentaries\"],\n",
        "                                           label=\"Primary Genre\", value=\"Action & Adventure\")\n",
        "                    pred_year = gr.Slider(1990, 2024, value=2023, label=\"Release Year\")\n",
        "                    pred_duration = gr.Slider(60, 300, value=120, label=\"Duration (minutes)\")\n",
        "\n",
        "            predict_btn = gr.Button(\"🎯 Predict Content Success\", variant=\"secondary\")\n",
        "            prediction_result = gr.Textbox(label=\"Prediction Results\", lines=15, show_label=True, container=True)\n",
        "\n",
        "        with gr.Tab(\"🎯 ML: Recommendations\"):\n",
        "            gr.Markdown(\"## 🎯 Machine Learning: Content Recommendation System\")\n",
        "\n",
        "            build_rec_btn = gr.Button(\"🚀 Build Recommendation System\", variant=\"primary\", size=\"lg\")\n",
        "            rec_results = gr.Textbox(label=\"Recommendation System Results\", lines=15, max_lines=25, show_label=True, container=True)\n",
        "\n",
        "            gr.Markdown(\"### 🔍 Get Content Recommendations\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    title_input = gr.Textbox(label=\"Enter Content Title\", placeholder=\"e.g., Stranger Things, Bird Box, Roma\")\n",
        "                    num_recs = gr.Slider(3, 10, value=5, label=\"Number of Recommendations\")\n",
        "                with gr.Column():\n",
        "                    get_rec_btn = gr.Button(\"🎬 Get Recommendations\", variant=\"secondary\")\n",
        "                    rec_output = gr.Textbox(label=\"Recommendations\", lines=20, show_label=True, container=True)\n",
        "\n",
        "        # Event handlers\n",
        "        load_btn.click(analyzer.load_data, inputs=[file_input], outputs=[load_output])\n",
        "        clean_btn.click(analyzer.clean_data, outputs=[load_output])\n",
        "        get_summary_btn.click(analyzer.create_dashboard_summary, outputs=[summary_output])\n",
        "        sample_table_btn.click(analyzer.get_sample_data_table, outputs=[sample_table_output])\n",
        "\n",
        "        # SEPARATE BUTTON EVENT HANDLERS - This is the key change!\n",
        "        content_dist_btn.click(analyzer.content_distribution_analysis, outputs=[content_insights, content_plot])\n",
        "        ratings_dist_btn.click(analyzer.ratings_distribution_analysis, outputs=[ratings_insights, ratings_plot])\n",
        "\n",
        "        countries_btn.click(analyzer.countries_analysis, outputs=[countries_insights, countries_plot])\n",
        "        directors_btn.click(analyzer.directors_analysis, outputs=[directors_insights, directors_plot])\n",
        "        genres_btn.click(analyzer.genres_analysis, outputs=[genres_insights, genres_plot])\n",
        "\n",
        "        # NEW FEATURE: Movie Details Lookup\n",
        "        get_movie_details_btn.click(analyzer.get_movie_details, inputs=[movie_title_input], outputs=[movie_details_output])\n",
        "\n",
        "        # ML event handlers\n",
        "        train_model_btn.click(analyzer.train_success_prediction_model, outputs=[ml_results, ml_plot])\n",
        "        predict_btn.click(analyzer.predict_content_success,\n",
        "                         inputs=[pred_type, pred_country, pred_rating, pred_genre, pred_year, pred_duration],\n",
        "                         outputs=[prediction_result])\n",
        "        build_rec_btn.click(analyzer.build_recommendation_system, outputs=[rec_results])\n",
        "        get_rec_btn.click(analyzer.get_recommendations, inputs=[title_input, num_recs], outputs=[rec_output])\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Launch the application\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🚀 Starting Enhanced Netflix Data Analysis Dashboard...\")\n",
        "    print(\"📊 Sample data included - you can test immediately!\")\n",
        "    print(\"🎭 NEW: Enhanced Genres Analysis with genre count per content and top genre\")\n",
        "    print(\"🎬 NEW: Top 10 Directors Analysis\")\n",
        "    print(\"🔍 NEW: Movie Details Lookup with Genre Count & Duration Analysis\")\n",
        "\n",
        "    # Create and launch the interface\n",
        "    demo = create_interface()\n",
        "    demo.launch(share=True, server_name=\"0.0.0.0\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "AlK-489mMM_B",
        "outputId": "12a4b25e-d6af-4133-a4a2-b027172783ee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting Enhanced Netflix Data Analysis Dashboard...\n",
            "📊 Sample data included - you can test immediately!\n",
            "🎭 NEW: Enhanced Genres Analysis with genre count per content and top genre\n",
            "🎬 NEW: Top 10 Directors Analysis\n",
            "🔍 NEW: Movie Details Lookup with Genre Count & Duration Analysis\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://394142ec5921e5d605.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://394142ec5921e5d605.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}